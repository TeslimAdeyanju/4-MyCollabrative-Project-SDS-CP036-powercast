{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a443f22b",
   "metadata": {},
   "source": [
    "# Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8dc16",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6206cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure the common module can be imported\n",
    "# Adjust the path to point to the common directory\n",
    "# Get the parent directory of the project (one level above week-2/)\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from common.load_data import load_data\n",
    "from common.time_based_features import add_time_based_features\n",
    "from common.lag_and_rolling_statistics import engineer_lag_and_rolling\n",
    "from common.scale_features import scale_features\n",
    "from common.chronological_split import chronological_train_test_split\n",
    "from common.linear_regression import baseline_model_performance\n",
    "from common.persistence_model import persistence_baseline_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284d161",
   "metadata": {},
   "source": [
    "### Pipeline Overview:\n",
    "- Load dataset from CSV and parse datetime index (ensuring chronological order)\n",
    "- Add time-based features (month, weekday, hour, is_weekend) to help capture temporal patterns\n",
    "- Engineer lagged and rolling statistical features per zone to provide historical context\n",
    "- split the dataset chronologically into train and test sets to prevent data leakage and preserve time sequence\n",
    "- finally, normalize numerical features (including engineered features) using StandardScaler for stable training\n",
    "Note: All preprocessing is done BEFORE the train/test split to ensure consistent feature transformations.\n",
    "The chronological split maintains the temporal integrity essential for time series modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a09dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 'DateTime' as datetime index column\n",
      "\n",
      "Performance metrics for Zone 1 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  454.367351\n",
      "1    MAE  339.725092\n",
      "2     R2    0.994571\n",
      "\n",
      "Performance metrics for Zone 2 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  379.034880\n",
      "1    MAE  285.118287\n",
      "2     R2    0.995222\n",
      "\n",
      "Performance metrics for Zone 3 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  291.706884\n",
      "1    MAE  211.576803\n",
      "2     R2    0.992183\n"
     ]
    }
   ],
   "source": [
    "zones = [\n",
    "    'Zone 1 Power Consumption',\n",
    "    'Zone 2 Power Consumption',\n",
    "    'Zone 3 Power Consumption'\n",
    "]\n",
    "\n",
    "# Load and preprocess data\n",
    "dataset = (\n",
    "    load_data(file_path='..\\Data\\Tetuan City power consumption.csv')\n",
    "    .pipe(add_time_based_features)\n",
    ")\n",
    "\n",
    "dataset_full = dataset.copy()\n",
    "for zone in zones:\n",
    "    dataset_full = engineer_lag_and_rolling(dataset_full, zone, lags=[1], rolling_windows=[3])\n",
    "\n",
    "# Split chronologically AFTER feature engineering\n",
    "dataset_train, dataset_test = chronological_train_test_split(dataset_full, split_ratio=0.8)\n",
    "\n",
    "# Split BEFORE creating lags/rolling\n",
    "dataset_train, dataset_test = chronological_train_test_split(dataset, split_ratio=0.8)\n",
    "\n",
    "for zone in zones:\n",
    "    # Feature engineering ONLY for this zone\n",
    "    train_zone = engineer_lag_and_rolling(dataset_train, zone, lags=[1], rolling_windows=[3])\n",
    "    test_zone = engineer_lag_and_rolling(dataset_test, zone, lags=[1], rolling_windows=[3])\n",
    "\n",
    "    # Scale features\n",
    "    train_scaled, test_scaled, scaler, feature_cols = scale_features(\n",
    "        train_zone, test_zone, target_col=zone\n",
    "    )\n",
    "\n",
    "    # Train & evaluate\n",
    "    performance = baseline_model_performance(\n",
    "        train_dataset=train_scaled,\n",
    "        test_dataset=test_scaled,\n",
    "        target_col=zone,\n",
    "        feature_cols=feature_cols\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPerformance metrics for {zone}:\")\n",
    "    print(performance['metrics'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a848e",
   "metadata": {},
   "source": [
    "#### Interpretation per zone\n",
    "**RMSE**: Root Mean Squared Error  \n",
    "**MAE**: Mean Absolute Error  \n",
    "**R2**: Coefficient of Determination - a statistical measure that tells how much of the variance in the target variable.\n",
    "\n",
    "\n",
    "- **Zone 1**\n",
    "  - RMSE: ~454.37\n",
    "  - MAE: ~339.73\n",
    "  - R²: 0.9946 → The model explains 99.46% of the variance, which is huge (near-perfect).\n",
    "\n",
    "- **Zone 2**\n",
    "  - RMSE: ~379.03\n",
    "  - MAE: ~285.12\n",
    "  - R²: 0.9952 → Best-performing zone, suggesting Zone 2’s patterns are the most predictable from its own history.\n",
    "\n",
    "- **Zone 3**\n",
    "  - RMSE: ~291.71\n",
    "  - MAE: ~211.58.70\n",
    "  - R²: 0.9921 → Slightly more error than Zone 2 but still very high predictive power.\n",
    "\n",
    "In time series, high R² is due to strong autocorrelation (yesterday’s consumption a very good predictor for today).\n",
    "\n",
    "Adding Persistence model = baseline of “no model” — just using previous value as prediction - to compare how the linear regression baseline model is compared to baseline persistence model - using yesterday's value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac5f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence baseline metrics for Zone 1 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  549.974681\n",
      "1    MAE  369.605858\n",
      "2     R2    0.992046\n",
      "\n",
      "Persistence baseline metrics for Zone 2 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  459.747095\n",
      "1    MAE  307.673258\n",
      "2     R2    0.992971\n",
      "\n",
      "Persistence baseline metrics for Zone 3 Power Consumption:\n",
      "  Metric       Value\n",
      "0   RMSE  338.884857\n",
      "1    MAE  201.406095\n",
      "2     R2    0.989449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Feature engineering ONLY for this zone\n",
    "    test_zone = engineer_lag_and_rolling(dataset_test, zone, lags=[1, 3], rolling_windows=[3, 7])\n",
    "\n",
    "    metrics = persistence_baseline_performance(\n",
    "        test_zone, target_col=zone, lag=1)\n",
    "    print(f\"Persistence baseline metrics for {zone}:\")\n",
    "    print(metrics)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c2384",
   "metadata": {},
   "source": [
    "### Analysis of Linear Regression vs. Persistence Model Performance\n",
    "\n",
    "From the above results - `Linear Regression (lag-1)` model significantly out performs the `Persistence (naïve)` model across all zones.\n",
    "\n",
    "\n",
    "| Zone   | Model              | RMSE     | MAE      | R²       | Improvement vs. Persistence               |\n",
    "|--------|--------------------|----------|----------|----------|------------------------------------------|\n",
    "| Zone 1 | Linear Regression  | 454.37   | 339.73   | 0.9946   | RMSE ↓17.4%, MAE ↓8.1%, R² ↑0.25%       |\n",
    "| Zone 1 | Persistence        | 549.97   | 369.61   | 0.9920   | (Baseline)                               |\n",
    "| Zone 2 | Linear Regression  | 379.03   | 285.12   | 0.9952   | RMSE ↓17.6%, MAE ↓7.3%, R² ↑0.23%       |\n",
    "| Zone 2 | Persistence        | 459.75   | 307.67   | 0.9930   | (Baseline)                               |\n",
    "| Zone 3 | Linear Regression  | 291.71   | 211.58   | 0.9922   | RMSE ↓13.9%, MAE ↑5.1%, R² ↑0.28%       |\n",
    "| Zone 3 | Persistence        | 338.88   | 201.41   | 0.9894   | (Baseline)                               |\n",
    "\n",
    "**Persistence model** (minimal benchmark) is used to verify that LinearRegression baseline model adds value (which it does).  \n",
    "**Data** has structure (trends/scaling effects) that Persistence misses.  \n",
    "**Data Characteristics**\n",
    "- Strong autocorrelation: The next value heavily depends on the current one.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDS-CP036-powercast (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
